{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import torch\n",
        "\n",
        "from scipy.sparse.linalg import lsqr\n",
        "from scipy.sparse.linalg import LinearOperator\n",
        "\n",
        "from gapat.algorithms import recon\n",
        "from gapat.processings import negetive_processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define constants\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SQRT_3 = 1.7321\n",
        "PI = 3.1415926536\n",
        "N_SEARCH_SPACE_SIZE = 100\n",
        "UPSAMPLE_FACTOR = 2\n",
        "\n",
        "# Define paths\n",
        "DATA_PATH = \"data/sensor_Liver_data_matrix.mat\"\n",
        "LOCATION_PATH = \"data/sensor_Liver_location.mat\"\n",
        "MBPD_RESULT_PATH = \"results/result_mbpd_Liver.mat\"\n",
        "SI_TABLE_PATH = \"data/sphere_integral_table.mat\"\n",
        "SI_GRAD_TABLE_PATH = \"data/sphere_integral_gradd_table.mat\"\n",
        "\n",
        "DATA_VAR = \"simulation_data\"\n",
        "LOCATION_VAR = \"detector_locations\"\n",
        "MBPD_RESULT_VAR = \"x_volume\"\n",
        "SI_TABLE_VAR = \"sphere_integral_table\"\n",
        "SI_GRAD_TABLE_VAR = \"sphere_integral_gradd_table\"\n",
        "\n",
        "# Define variables\n",
        "x_range = [-12.80e-3, 12.80e-3]\n",
        "y_range = [-12.80e-3, 12.80e-3]\n",
        "z_range = [-6.40e-3, 6.40e-3]\n",
        "res = 0.10e-3\n",
        "vs = 1510.0\n",
        "fs = 8.333333e6\n",
        "fs = fs * UPSAMPLE_FACTOR\n",
        "dt = 1 / fs\n",
        "x_start = x_range[0]\n",
        "x_end = x_range[1]\n",
        "y_start = y_range[0]\n",
        "y_end = y_range[1]\n",
        "z_start = z_range[0]\n",
        "z_end = z_range[1]\n",
        "num_x = int(round((x_end - x_start) / res))\n",
        "num_y = int(round((y_end - y_start) / res))\n",
        "num_z = int(round((z_end - z_start) / res))\n",
        "num_voxels = num_x * num_y * num_z\n",
        "X, Y, Z = torch.meshgrid(\n",
        "    torch.linspace(x_start, x_end - res, num_x, device=DEVICE),\n",
        "    torch.linspace(y_start, y_end - res, num_y, device=DEVICE),\n",
        "    torch.linspace(z_start, z_end - res, num_z, device=DEVICE),\n",
        "    indexing=\"ij\",\n",
        ")\n",
        "voxel_locations = torch.stack([X.flatten(), Y.flatten(), Z.flatten()], dim=1)\n",
        "time_interval_length = int(2.0 * SQRT_3 * res / vs * fs) + 1\n",
        "alpha_interval = PI / 2.0 / N_SEARCH_SPACE_SIZE\n",
        "beta_interval = PI / 2.0 / N_SEARCH_SPACE_SIZE\n",
        "d_interval = res * 4.0 / N_SEARCH_SPACE_SIZE\n",
        "\n",
        "# Load simulation data and convert to torch.Tensor\n",
        "detector_locations = (\n",
        "    torch.from_numpy(sio.loadmat(LOCATION_PATH)[LOCATION_VAR]).to(DEVICE).contiguous()\n",
        ")\n",
        "\n",
        "# Linear interpolation along the time dimension\n",
        "_sim_np = sio.loadmat(DATA_PATH)[DATA_VAR]\n",
        "_sim_torch = torch.from_numpy(_sim_np)\n",
        "_sim_torch = torch.nn.functional.interpolate(\n",
        "    _sim_torch.unsqueeze(0),\n",
        "    scale_factor=UPSAMPLE_FACTOR,\n",
        "    mode=\"linear\",\n",
        "    align_corners=True,\n",
        ").squeeze(0)\n",
        "simulation_data = _sim_torch.to(DEVICE).contiguous()\n",
        "\n",
        "# Sort data by detector z-coordinate\n",
        "sorted_indices = torch.argsort(detector_locations[:, 2], descending=True)\n",
        "detector_locations = detector_locations[sorted_indices].contiguous()\n",
        "simulation_data = simulation_data[sorted_indices].contiguous()\n",
        "num_detectors, num_times = simulation_data.shape\n",
        "\n",
        "# Load sphere integral lookup tables and convert to torch.Tensor\n",
        "sphere_integral_table = (\n",
        "    torch.from_numpy(sio.loadmat(SI_TABLE_PATH)[SI_TABLE_VAR]).to(DEVICE).contiguous()\n",
        ")\n",
        "sphere_integral_gradd_table = (\n",
        "    torch.from_numpy(sio.loadmat(SI_GRAD_TABLE_PATH)[SI_GRAD_TABLE_VAR])\n",
        "    .to(DEVICE)\n",
        "    .contiguous()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define forward operator\n",
        "@torch.inference_mode()\n",
        "def _forward_operator(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Forward operator A * x\n",
        "    \"\"\"\n",
        "    y = torch.zeros(num_detectors * num_times, device=DEVICE)\n",
        "    for det_idx in range(num_detectors):\n",
        "        voxel_to_det_vectors = detector_locations[det_idx, :] - voxel_locations\n",
        "        voxel_to_det_distances = torch.norm(voxel_to_det_vectors, dim=1)\n",
        "        time_starts = torch.floor(\n",
        "            (voxel_to_det_distances - SQRT_3 * res) / vs * fs\n",
        "        ).int()\n",
        "        alpha_idxs = (\n",
        "            (\n",
        "                torch.atan(voxel_to_det_vectors[:, 1] / (voxel_to_det_vectors[:, 0]))\n",
        "                / alpha_interval\n",
        "            )\n",
        "            .abs()\n",
        "            .int()\n",
        "            .clamp(0, N_SEARCH_SPACE_SIZE - 1)\n",
        "        )\n",
        "        beta_idxs = (\n",
        "            (\n",
        "                torch.atan(\n",
        "                    voxel_to_det_vectors[:, 2]\n",
        "                    / (torch.norm(voxel_to_det_vectors[:, :2], dim=1))\n",
        "                )\n",
        "                / beta_interval\n",
        "            )\n",
        "            .abs()\n",
        "            .int()\n",
        "            .clamp(0, N_SEARCH_SPACE_SIZE - 1)\n",
        "        )\n",
        "        for i in range(time_interval_length):\n",
        "            time_idxs = time_starts + i\n",
        "            d_idxs = (\n",
        "                ((voxel_to_det_distances - vs * time_idxs * dt) / d_interval).int()\n",
        "                + N_SEARCH_SPACE_SIZE // 2\n",
        "            ).clamp(0, N_SEARCH_SPACE_SIZE - 1)\n",
        "            I = sphere_integral_table[d_idxs, alpha_idxs, beta_idxs]\n",
        "            dI = sphere_integral_gradd_table[d_idxs, alpha_idxs, beta_idxs]\n",
        "            y.scatter_add_(\n",
        "                0,\n",
        "                (det_idx * num_times + time_idxs).long(),\n",
        "                -vs / (vs * dt * time_idxs) * (I / (vs * dt * time_idxs) + dI) * x,\n",
        "            )\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define transpose operator\n",
        "@torch.inference_mode()\n",
        "def _transpose_operator(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Transpose operator A^T * x\n",
        "    \"\"\"\n",
        "    y = torch.zeros(num_voxels, device=DEVICE)\n",
        "    for det_idx in range(num_detectors):\n",
        "        voxel_to_det_vectors = detector_locations[det_idx, :] - voxel_locations\n",
        "        voxel_to_det_distances = torch.norm(voxel_to_det_vectors, dim=1)\n",
        "        time_starts = torch.floor(\n",
        "            (voxel_to_det_distances - SQRT_3 * res) / vs * fs\n",
        "        ).int()\n",
        "        alpha_idxs = (\n",
        "            (\n",
        "                torch.atan(voxel_to_det_vectors[:, 1] / (voxel_to_det_vectors[:, 0]))\n",
        "                / alpha_interval\n",
        "            )\n",
        "            .abs()\n",
        "            .int()\n",
        "            .clamp(0, N_SEARCH_SPACE_SIZE - 1)\n",
        "        )\n",
        "        beta_idxs = (\n",
        "            (\n",
        "                torch.atan(\n",
        "                    voxel_to_det_vectors[:, 2]\n",
        "                    / (torch.norm(voxel_to_det_vectors[:, :2], dim=1))\n",
        "                )\n",
        "                / beta_interval\n",
        "            )\n",
        "            .abs()\n",
        "            .int()\n",
        "            .clamp(0, N_SEARCH_SPACE_SIZE - 1)\n",
        "        )\n",
        "        for i in range(time_interval_length):\n",
        "            time_idxs = time_starts + i\n",
        "            d_idxs = (\n",
        "                ((voxel_to_det_distances - vs * time_idxs * dt) / d_interval).int()\n",
        "                + N_SEARCH_SPACE_SIZE // 2\n",
        "            ).clamp(0, N_SEARCH_SPACE_SIZE - 1)\n",
        "            I = sphere_integral_table[d_idxs, alpha_idxs, beta_idxs]\n",
        "            dI = sphere_integral_gradd_table[d_idxs, alpha_idxs, beta_idxs]\n",
        "            y += (\n",
        "                -vs\n",
        "                / (vs * dt * time_idxs)\n",
        "                * (I / (vs * dt * time_idxs) + dI)\n",
        "                * x[det_idx * num_times + time_idxs]\n",
        "            )\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the linear operator required by the LSQR algorithm\n",
        "def Ax_ATx_operator(x, flag):\n",
        "    \"\"\"\n",
        "    GPU-optimized linear operator for computing A and A^T matrix-vector products.\n",
        "\n",
        "    Args:\n",
        "        x: torch.Tensor, input vector\n",
        "        flag: str, computation direction, \"notransp\" for A * x, \"transp\" for A^T * x\n",
        "\n",
        "    Returns:\n",
        "        y: numpy.ndarray, output vector\n",
        "    \"\"\"\n",
        "    if isinstance(x, np.ndarray):\n",
        "        x = torch.from_numpy(x).to(dtype=torch.float32, device=DEVICE)\n",
        "    else:\n",
        "        x = x.to(dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "    if flag == \"notransp\":\n",
        "        # Forward operation: A * x (batched GPU implementation)\n",
        "        result = _forward_operator(x)\n",
        "        return result.cpu().numpy()\n",
        "    elif flag == \"transp\":\n",
        "        # Transpose operation: A^T * x (batched GPU implementation)\n",
        "        result = _transpose_operator(x)\n",
        "        return result.cpu().numpy()\n",
        "    else:\n",
        "        raise ValueError(\"flag must be 'notransp' or 'transp'\")\n",
        "\n",
        "\n",
        "A_operator = LinearOperator(\n",
        "    shape=(num_detectors * num_times, num_voxels),\n",
        "    matvec=lambda x: Ax_ATx_operator(x, \"notransp\"),\n",
        "    rmatvec=lambda x: Ax_ATx_operator(x, \"transp\"),\n",
        "    dtype=np.float32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main program\n",
        "print(\"=\" * 60)\n",
        "print(\"Starting 3D Image Reconstruction Using LSQR Algorithm\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Data preprocessing: convert simulation data to column vector\n",
        "print(\"Data preprocessing...\")\n",
        "b = simulation_data.flatten().cpu().numpy().astype(np.float32)\n",
        "print(f\"Observation data shape: {b.shape}\")\n",
        "print(f\"Observation data range: [{b.min():.6f}, {b.max():.6f}]\")\n",
        "print(f\"Observation data non-zero elements: {np.count_nonzero(b)}/{len(b)}\")\n",
        "\n",
        "# Set LSQR algorithm parameters\n",
        "max_iter = 100  # Maximum number of iterations\n",
        "tolerance = 1.0e-5  # Convergence tolerance\n",
        "print(f\"\\nLSQR parameter settings:\")\n",
        "print(f\"Maximum iterations: {max_iter}\")\n",
        "print(f\"Convergence tolerance: {tolerance}\")\n",
        "print(f\"Number of reconstruction voxels: {num_voxels}\")\n",
        "\n",
        "# Reset GPU memory statistics\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Perform LSQR reconstruction\n",
        "print(f\"\\nStarting LSQR reconstruction...\")\n",
        "\n",
        "start_event = torch.cuda.Event(enable_timing=True)\n",
        "end_event = torch.cuda.Event(enable_timing=True)\n",
        "start_event.record()\n",
        "\n",
        "x_reconstructed, exit_reason, itn, r1norm, r2norm, anorm, acond, arnorm, xnorm, var = (\n",
        "    lsqr(\n",
        "        A_operator,\n",
        "        b,\n",
        "        iter_lim=max_iter,\n",
        "        atol=tolerance,\n",
        "        btol=tolerance,\n",
        "        show=False,  # Show iteration progress\n",
        "        damp=3e2,\n",
        "    )\n",
        ")\n",
        "\n",
        "end_event.record()\n",
        "end_event.synchronize()\n",
        "\n",
        "# Get GPU memory statistics\n",
        "peak_mem = torch.cuda.max_memory_allocated()\n",
        "\n",
        "print(f\"\\nLSQR reconstruction completed!\")\n",
        "print(f\"Reconstruction time: {start_event.elapsed_time(end_event) / 1000:.3f} s\")\n",
        "print(f\"Peak GPU memory usage: {peak_mem / 1024**2:.2f} MB\")\n",
        "print(f\"Number of iterations: {itn}\")\n",
        "print(f\"Exit reason: {exit_reason}\")\n",
        "print(f\"Residual norm: {r1norm:.6e}\")\n",
        "print(f\"Solution norm: {xnorm:.6e}\")\n",
        "\n",
        "# Reshape reconstruction result to 3D volume\n",
        "x_volume = x_reconstructed.reshape(num_x, num_y, num_z)\n",
        "x_volume = negetive_processing(x_volume)\n",
        "sio.savemat(MBPD_RESULT_PATH, {MBPD_RESULT_VAR: x_volume})\n",
        "losses = []\n",
        "print(f\"\\nReconstruction result statistics:\")\n",
        "print(f\"Reconstructed volume shape: {x_volume.shape}\")\n",
        "print(f\"Reconstructed value range: [{x_volume.min():.6f}, {x_volume.max():.6f}]\")\n",
        "print(f\"Reconstructed value mean: {x_volume.mean():.6f}\")\n",
        "print(f\"Reconstructed value std: {x_volume.std():.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# UBP reconstruction\n",
        "# detector_normals = torch.zeros(detector_locations.shape[0], 3, device=DEVICE)\n",
        "# detector_normals[:, 2] = -1.0\n",
        "detector_normals = -detector_locations\n",
        "result_ubp = recon(\n",
        "    simulation_data.cpu().numpy(),\n",
        "    detector_locations.cpu().numpy(),\n",
        "    detector_normals.cpu().numpy(),\n",
        "    x_range,\n",
        "    y_range,\n",
        "    z_range,\n",
        "    res,\n",
        "    vs,\n",
        "    fs,\n",
        "    method=\"ubp\",\n",
        ")\n",
        "result_ubp = negetive_processing(result_ubp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results\n",
        "plt.figure(figsize=(20, 10))\n",
        "cmap = \"hot\"\n",
        "\n",
        "# Plot UBP reconstruction z-axis MAP (Maximum Amplitude Projection)\n",
        "plt.subplot(2, 3, 1)\n",
        "ubp_map = result_ubp.max(axis=2)  # Maximum intensity projection along z-axis\n",
        "plt.imshow(\n",
        "    ubp_map.T,\n",
        "    cmap=cmap,\n",
        "    aspect=\"equal\",\n",
        "    origin=\"lower\",\n",
        "    extent=[x_start * 1e3, x_end * 1e3, y_start * 1e3, y_end * 1e3],\n",
        ")\n",
        "plt.colorbar(label=\"Intensity (a.u.)\")\n",
        "plt.xlabel(\"X (mm)\")\n",
        "plt.ylabel(\"Y (mm)\")\n",
        "plt.title(\"UBP Reconstruction - Z-axis MAP\")\n",
        "\n",
        "# Plot MB-PD reconstruction z-axis MAP (Maximum Amplitude Projection)\n",
        "plt.subplot(2, 3, 2)\n",
        "mbpd_map = x_volume.max(axis=2)  # Maximum intensity projection along z-axis\n",
        "plt.imshow(\n",
        "    mbpd_map.T,\n",
        "    cmap=cmap,\n",
        "    aspect=\"equal\",\n",
        "    origin=\"lower\",\n",
        "    extent=[x_start * 1e3, x_end * 1e3, y_start * 1e3, y_end * 1e3],\n",
        ")\n",
        "plt.colorbar(label=\"Intensity (a.u.)\")\n",
        "plt.xlabel(\"X (mm)\")\n",
        "plt.ylabel(\"Y (mm)\")\n",
        "plt.title(\"MB-PD Reconstruction - Z-axis MAP\")\n",
        "\n",
        "# Plot complete loss curve\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(losses, \"b-\", linewidth=2)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Complete Loss Curve\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.yscale(\"log\")\n",
        "\n",
        "# Plot UBP reconstruction z-axis center slice\n",
        "plt.subplot(2, 3, 4)\n",
        "center_z_idx = num_z // 2\n",
        "ubp_slice = result_ubp[:, :, center_z_idx]\n",
        "plt.imshow(\n",
        "    ubp_slice.T,\n",
        "    cmap=cmap,\n",
        "    aspect=\"equal\",\n",
        "    origin=\"lower\",\n",
        "    extent=[x_start * 1e3, x_end * 1e3, y_start * 1e3, y_end * 1e3],\n",
        ")\n",
        "plt.colorbar(label=\"Intensity (a.u.)\")\n",
        "plt.xlabel(\"X (mm)\")\n",
        "plt.ylabel(\"Y (mm)\")\n",
        "plt.title(\n",
        "    f\"UBP Reconstruction - Center Slice (z={z_start*1e3 + center_z_idx*res*1e3:.2f} mm)\"\n",
        ")\n",
        "\n",
        "# Plot MB-PD reconstruction z-axis center slice\n",
        "plt.subplot(2, 3, 5)\n",
        "center_z_idx = num_z // 2\n",
        "mbpd_slice = x_volume[:, :, center_z_idx]\n",
        "plt.imshow(\n",
        "    mbpd_slice.T,\n",
        "    cmap=cmap,\n",
        "    aspect=\"equal\",\n",
        "    origin=\"lower\",\n",
        "    extent=[x_start * 1e3, x_end * 1e3, y_start * 1e3, y_end * 1e3],\n",
        ")\n",
        "plt.colorbar(label=\"Intensity (a.u.)\")\n",
        "plt.xlabel(\"X (mm)\")\n",
        "plt.ylabel(\"Y (mm)\")\n",
        "plt.title(\n",
        "    f\"MB-PD Reconstruction - Center Slice (z={z_start*1e3 + center_z_idx*res*1e3:.2f} mm)\"\n",
        ")\n",
        "\n",
        "# Plot loss curve for the last 10 iterations\n",
        "plt.subplot(2, 3, 6)\n",
        "last_n = min(10, len(losses))\n",
        "plt.plot(\n",
        "    range(len(losses) - last_n, len(losses)),\n",
        "    losses[-last_n:],\n",
        "    \"r-\",\n",
        "    linewidth=2,\n",
        "    marker=\"o\",\n",
        ")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(f\"Last {last_n} Iterations Loss Curve\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Display results\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
