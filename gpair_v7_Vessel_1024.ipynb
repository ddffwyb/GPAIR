{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ed931fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "from gapat.algorithms import recon\n",
        "from gapat.processings import negetive_processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6178ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define constants\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PI = 3.1415926536\n",
        "GAUSSIAN_PEAK_INTENSITY = 0.4000222589 / 1000000.0  # 1/(sqrt(2*pi)*0.9973)/1000000\n",
        "SCALE_FACTOR = 1.0e3  # Scale factor for the raw signal\n",
        "MIN_HALF_KERNEL_SIZE = 12  # Ensures at least 4 time samples per sigma in the Gaussian kernel\n",
        "MIN_NUM_BLOCK = 8192  # Minimum number of thread blocks\n",
        "MAX_SPLIT_K = 1024  # Maximum Split-K partitions\n",
        "\n",
        "# Define paths\n",
        "DATA_PATH = \"data/sensor_Vessel_data_matrix_1024.mat\"\n",
        "LOCATION_PATH = \"data/sensor_Vessel_location_1024.mat\"\n",
        "GPAIR_RESULT_PATH = \"results/gpair_v7_Vessel_1024.mat\"\n",
        "UBP_RESULT_PATH = \"results/result_ubp_Vessel_1024.mat\"\n",
        "\n",
        "DATA_VAR = \"simulation_data\"\n",
        "LOCATION_VAR = \"detector_locations\"\n",
        "GPAIR_RESULT_VAR = \"x_3d\"\n",
        "UBP_RESULT_VAR = \"result_ubp\"\n",
        "\n",
        "# Define variables\n",
        "x_range = [-25.60e-3, 25.60e-3]\n",
        "y_range = [-25.60e-3, 25.60e-3]\n",
        "z_range = [-12.80e-3, 12.80e-3]\n",
        "res = 0.10e-3\n",
        "vs = 1500.0\n",
        "fs = 40.0e6\n",
        "x_start = x_range[0]\n",
        "x_end = x_range[1]\n",
        "y_start = y_range[0]\n",
        "y_end = y_range[1]\n",
        "z_start = z_range[0]\n",
        "z_end = z_range[1]\n",
        "num_x = int(round((x_end - x_start) / res))\n",
        "num_y = int(round((y_end - y_start) / res))\n",
        "num_z = int(round((z_end - z_start) / res))\n",
        "num_voxels = num_x * num_y * num_z\n",
        "\n",
        "# Load data\n",
        "detector_locations = (\n",
        "    torch.from_numpy(sio.loadmat(LOCATION_PATH)[LOCATION_VAR]).to(DEVICE).contiguous()\n",
        ")\n",
        "simulation_data = (\n",
        "    torch.from_numpy(sio.loadmat(DATA_PATH)[DATA_VAR]).to(DEVICE).contiguous()\n",
        "    * SCALE_FACTOR\n",
        ")\n",
        "\n",
        "# Sort data by detector z-coordinate\n",
        "sorted_indices = torch.argsort(detector_locations[:, 2], descending=True)\n",
        "detector_locations = detector_locations[sorted_indices].contiguous()\n",
        "simulation_data = simulation_data[sorted_indices].contiguous()\n",
        "num_detectors, num_times = simulation_data.shape\n",
        "\n",
        "# Detector coordinates use SoA layout for improved coalesced memory access\n",
        "detector_x = detector_locations[:, 0].contiguous()\n",
        "detector_y = detector_locations[:, 1].contiguous()\n",
        "detector_z = detector_locations[:, 2].contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd3eb4e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate convolution kernel\n",
        "def generate_adaptive_conv_kernel(res, vs, fs):\n",
        "    time_interval_length_half = int(3.0 * res / vs * fs + 1)\n",
        "    adaptive_ratio = int(MIN_HALF_KERNEL_SIZE / time_interval_length_half + 1)\n",
        "    time_interval_length_half = time_interval_length_half * adaptive_ratio\n",
        "    fs = fs * adaptive_ratio\n",
        "    const_factor = 2.0 * PI * GAUSSIAN_PEAK_INTENSITY * vs / res\n",
        "    conv_input = (\n",
        "        vs\n",
        "        / fs\n",
        "        * torch.arange(\n",
        "            time_interval_length_half,\n",
        "            -time_interval_length_half - 1,\n",
        "            -1,\n",
        "            device=DEVICE,\n",
        "            dtype=torch.float32,\n",
        "        )\n",
        "    )\n",
        "    conv_kernel = (\n",
        "        (const_factor * conv_input * torch.exp(-(conv_input**2) / (2.0 * res**2)))\n",
        "        .unsqueeze(0)\n",
        "        .unsqueeze(0)\n",
        "    )\n",
        "    return conv_kernel, time_interval_length_half, adaptive_ratio\n",
        "\n",
        "\n",
        "# Compute convolution kernel and upsampling parameters\n",
        "conv_kernel, time_interval_length_half, adaptive_ratio = generate_adaptive_conv_kernel(\n",
        "    res, vs, fs\n",
        ")\n",
        "num_times_upsampled = num_times * adaptive_ratio\n",
        "dd_inv_upsampled = fs * adaptive_ratio / vs\n",
        "stride_out_d = num_times_upsampled\n",
        "stride_dx_d = num_times_upsampled\n",
        "print(f\"adaptive_ratio={adaptive_ratio}, num_times_upsampled={num_times_upsampled}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15cb9bc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate dynamic Split-K partition count\n",
        "def generate_dynamic_split_k(num_detectors):\n",
        "    split_k = max(1, (MIN_NUM_BLOCK + num_detectors - 1) // num_detectors)\n",
        "    split_k = min(split_k, MAX_SPLIT_K)\n",
        "    split_k = 2 ** int(math.log2(split_k) + 0.5)\n",
        "    return split_k\n",
        "\n",
        "\n",
        "# Compute Split-K partition count\n",
        "split_k = generate_dynamic_split_k(num_detectors)\n",
        "print(f\"[forward] split_k={split_k}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff145c50",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== Autotune Configuration ====================\n",
        "# Forward operator optimization key points:\n",
        "# 1) Detector blocking (BLOCK_DET): voxel/x data loaded once, reused for multiple detectors\n",
        "# 2) On-the-fly voxel coordinate computation (division/modulo): avoids global reads of 3 large voxel_x/y/z arrays\n",
        "@triton.autotune(\n",
        "    configs=[\n",
        "        triton.Config({\"BLOCK_VOXEL\": 256, \"BLOCK_DET\": 4}, num_stages=3, num_warps=4),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 256, \"BLOCK_DET\": 8}, num_stages=3, num_warps=8),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 512, \"BLOCK_DET\": 4}, num_stages=4, num_warps=4),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 512, \"BLOCK_DET\": 8}, num_stages=4, num_warps=8),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 1024, \"BLOCK_DET\": 4}, num_stages=4, num_warps=8),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 1024, \"BLOCK_DET\": 8}, num_stages=4, num_warps=8),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 2048, \"BLOCK_DET\": 4}, num_stages=5, num_warps=8),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 256, \"BLOCK_DET\": 16}, num_stages=3, num_warps=8),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 512, \"BLOCK_DET\": 16}, num_stages=4, num_warps=8),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 256, \"BLOCK_DET\": 32}, num_stages=3, num_warps=8),\n",
        "    ],\n",
        "    key=[\"num_voxels\", \"num_detectors\", \"num_times_upsampled\", \"split_k\"],\n",
        ")\n",
        "@triton.jit\n",
        "def forward_kernel_splitk(\n",
        "    x_ptr,  # Input voxel data pointer [num_voxels]\n",
        "    detector_x_ptr,  # Detector X coordinate pointer [num_detectors] - SoA\n",
        "    detector_y_ptr,  # Detector Y coordinate pointer [num_detectors] - SoA\n",
        "    detector_z_ptr,  # Detector Z coordinate pointer [num_detectors] - SoA\n",
        "    partial_output_ptr,  # [split_k, num_detectors, num_times_upsampled] - independent output per split\n",
        "    num_voxels: tl.constexpr,  # Total number of voxels\n",
        "    num_detectors: tl.constexpr,  # Total number of detectors\n",
        "    num_times_upsampled: tl.constexpr,  # Number of upsampled time points\n",
        "    dd_inv_upsampled: tl.constexpr,  # Inverse of upsampled single time step distance\n",
        "    stride_partial_k: tl.constexpr,  # Split-K dimension stride of partial_output\n",
        "    stride_partial_d: tl.constexpr,  # Detector dimension stride of partial_output\n",
        "    split_k: tl.constexpr,  # Number of Split-K partitions\n",
        "    x_start: tl.constexpr,  # Voxel grid start x coordinate\n",
        "    y_start: tl.constexpr,  # Voxel grid start y coordinate\n",
        "    z_start: tl.constexpr,  # Voxel grid start z coordinate\n",
        "    res: tl.constexpr,  # Voxel grid resolution\n",
        "    num_y: tl.constexpr,  # Voxel grid y dimension size\n",
        "    num_z: tl.constexpr,  # Voxel grid y dimension size\n",
        "    BLOCK_VOXEL: tl.constexpr,  # Triton block size for voxels\n",
        "    BLOCK_DET: tl.constexpr,  # Number of detectors processed per program\n",
        "):\n",
        "    \"\"\"Split-K Triton implementation of forward operator A*x (detector blocking + on-the-fly voxel coordinates)\"\"\"\n",
        "    det_block_idx = tl.program_id(0)\n",
        "    split_k_idx = tl.program_id(1)\n",
        "\n",
        "    # Detector block for the current program\n",
        "    det_start = det_block_idx * BLOCK_DET\n",
        "    out_start = partial_output_ptr + split_k_idx * stride_partial_k\n",
        "\n",
        "    # Compute the voxel range for each split\n",
        "    voxels_per_split = tl.cdiv(num_voxels, split_k)\n",
        "    v_start_base = split_k_idx * voxels_per_split\n",
        "    v_end = tl.minimum(v_start_base + voxels_per_split, num_voxels)\n",
        "\n",
        "    # Precompute num_y * num_z for division\n",
        "    num_yz = num_y * num_z\n",
        "\n",
        "    # Software pipeline: num_stages configured by autotune\n",
        "    for v_start in tl.range(v_start_base, v_end, BLOCK_VOXEL):\n",
        "        v_offsets = v_start + tl.arange(0, BLOCK_VOXEL)\n",
        "        v_mask = v_offsets < v_end\n",
        "\n",
        "        # x loaded once, reused for BLOCK_DET detectors\n",
        "        x_val = tl.load(x_ptr + v_offsets, mask=v_mask, other=0.0)\n",
        "\n",
        "        # On-the-fly voxel coordinates (using division/modulo, supports arbitrary dimensions)\n",
        "        v = v_offsets.to(tl.int32)\n",
        "        z_idx = v % num_z\n",
        "        y_idx = (v // num_z) % num_y\n",
        "        x_idx = v // num_yz\n",
        "\n",
        "        vox_loc_x = x_start + x_idx * res\n",
        "        vox_loc_y = y_start + y_idx * res\n",
        "        vox_loc_z = z_start + z_idx * res\n",
        "\n",
        "        # Scalar detector loop: avoids register/local memory pressure from 2D broadcasting\n",
        "        for d in tl.static_range(0, BLOCK_DET):\n",
        "            det_id = det_start + d\n",
        "            d_mask = det_id < num_detectors\n",
        "\n",
        "            det_loc_x = tl.load(detector_x_ptr + det_id, mask=d_mask, other=0.0)\n",
        "            det_loc_y = tl.load(detector_y_ptr + det_id, mask=d_mask, other=0.0)\n",
        "            det_loc_z = tl.load(detector_z_ptr + det_id, mask=d_mask, other=0.0)\n",
        "\n",
        "            dx = det_loc_x - vox_loc_x\n",
        "            dy = det_loc_y - vox_loc_y\n",
        "            dz = det_loc_z - vox_loc_z\n",
        "\n",
        "            dist_sq = dx * dx + dy * dy + dz * dz\n",
        "            dist_inv = tl.rsqrt(dist_sq)\n",
        "\n",
        "            time_center = (dist_sq * dist_inv * dd_inv_upsampled + 0.5).to(tl.int32)\n",
        "            t_mask = (time_center >= 0) & (time_center < num_times_upsampled)\n",
        "\n",
        "            out_ptr = out_start + det_id * stride_partial_d + time_center\n",
        "            val_to_add = x_val * dist_inv\n",
        "            mask = t_mask & v_mask & d_mask\n",
        "            tl.atomic_add(out_ptr, val_to_add, mask=mask, sem=\"relaxed\")\n",
        "\n",
        "\n",
        "def forward_operator_triton(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Optimized Triton forward operator A*x (Split-K + detector blocking + on-the-fly voxel coordinates)\"\"\"\n",
        "    # Allocate partial_output buffer [split_k, num_detectors, num_times_upsampled]\n",
        "    partial_output = torch.zeros(\n",
        "        (split_k, num_detectors, num_times_upsampled),\n",
        "        device=DEVICE,\n",
        "        dtype=torch.float32,\n",
        "    )\n",
        "    stride_partial_k = num_detectors * num_times_upsampled\n",
        "    stride_partial_d = num_times_upsampled\n",
        "\n",
        "    # Grid: (detector_blocks, split_k); BLOCK_DET selected by autotune\n",
        "    grid = lambda META: (triton.cdiv(num_detectors, META[\"BLOCK_DET\"]), split_k)\n",
        "\n",
        "    forward_kernel_splitk[grid](\n",
        "        x,\n",
        "        detector_x,\n",
        "        detector_y,\n",
        "        detector_z,\n",
        "        partial_output,\n",
        "        num_voxels,\n",
        "        num_detectors,\n",
        "        num_times_upsampled,\n",
        "        dd_inv_upsampled,\n",
        "        stride_partial_k,\n",
        "        stride_partial_d,\n",
        "        split_k,\n",
        "        x_start,\n",
        "        y_start,\n",
        "        z_start,\n",
        "        res,\n",
        "        num_y,\n",
        "        num_z,\n",
        "    )\n",
        "\n",
        "    # Reduction: sum along the Split-K dimension\n",
        "    dy_upsampling_batch = partial_output.sum(dim=0)\n",
        "\n",
        "    # Convolution operation\n",
        "    dy_conv_transpose = torch.nn.functional.conv_transpose1d(\n",
        "        dy_upsampling_batch.unsqueeze(1),\n",
        "        conv_kernel,\n",
        "        padding=time_interval_length_half,\n",
        "    ).squeeze(1)\n",
        "\n",
        "    # Downsampling and flattening\n",
        "    y = dy_conv_transpose[:, ::adaptive_ratio].contiguous().flatten()\n",
        "    return y\n",
        "\n",
        "\n",
        "# ==================== Autotune Optimized Transpose Kernel ====================\n",
        "# Note: The transpose operator does not use the Split-K strategy for the following reasons:\n",
        "# 1. Each voxel is an independent output target, no write conflicts (no atomic_add needed)\n",
        "# 2. Accumulation is performed in registers, very efficient\n",
        "# 3. Sufficient voxel count (e.g., 256*256*128=8M), thread blocks already saturate the GPU\n",
        "# 4. Removing Split-K saves memory allocation and reduction overhead\n",
        "@triton.autotune(\n",
        "    configs=[\n",
        "        triton.Config({\"BLOCK_VOXEL\": 128}, num_stages=2, num_warps=4),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 256}, num_stages=3, num_warps=4),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 512}, num_stages=4, num_warps=8),\n",
        "        triton.Config({\"BLOCK_VOXEL\": 1024}, num_stages=4, num_warps=8),\n",
        "    ],\n",
        "    key=[\"num_voxels\", \"num_detectors\", \"num_times_upsampled\"],\n",
        ")\n",
        "@triton.jit\n",
        "def transpose_kernel(\n",
        "    dx_conv_ptr,  # [num_detectors, num_times_upsampled]\n",
        "    detector_x_ptr,  # Detector X coordinate pointer [num_detectors] - SoA\n",
        "    detector_y_ptr,  # Detector Y coordinate pointer [num_detectors] - SoA\n",
        "    detector_z_ptr,  # Detector Z coordinate pointer [num_detectors] - SoA\n",
        "    output_ptr,  # [num_voxels], direct output\n",
        "    num_voxels: tl.constexpr,  # Total number of voxels\n",
        "    num_detectors: tl.constexpr,  # Total number of detectors\n",
        "    num_times_upsampled: tl.constexpr,  # Number of upsampled time points\n",
        "    dd_inv_upsampled: tl.constexpr,  # Inverse of upsampled single time step distance\n",
        "    stride_dx_d: tl.constexpr,  # Stride of dx_conv\n",
        "    x_start: tl.constexpr,  # Voxel grid start x coordinate\n",
        "    y_start: tl.constexpr,  # Voxel grid start y coordinate\n",
        "    z_start: tl.constexpr,  # Voxel grid start z coordinate\n",
        "    res: tl.constexpr,  # Voxel grid resolution\n",
        "    num_y: tl.constexpr,  # Voxel grid y dimension size\n",
        "    num_z: tl.constexpr,  # Voxel grid z dimension size\n",
        "    BLOCK_VOXEL: tl.constexpr,  # # Triton block size for voxels\n",
        "):\n",
        "    \"\"\"Triton implementation of transpose operator A^T*x (on-the-fly voxel coordinate computation by index, avoiding reads of voxel_x/y/z)\"\"\"\n",
        "    voxel_block_idx = tl.program_id(0)\n",
        "\n",
        "    # Voxel block for the current program\n",
        "    v_start = voxel_block_idx * BLOCK_VOXEL\n",
        "    v_offsets = v_start + tl.arange(0, BLOCK_VOXEL)\n",
        "    v_mask = v_offsets < num_voxels\n",
        "\n",
        "    # Precompute num_y * num_z for division\n",
        "    num_yz = num_y * num_z\n",
        "\n",
        "    # On-the-fly voxel coordinates (using division/modulo, supports arbitrary dimensions)\n",
        "    v = v_offsets.to(tl.int32)\n",
        "    z_idx = v % num_z\n",
        "    y_idx = (v // num_z) % num_y\n",
        "    x_idx = v // num_yz\n",
        "\n",
        "    vox_loc_x = x_start + x_idx * res\n",
        "    vox_loc_y = y_start + y_idx * res\n",
        "    vox_loc_z = z_start + z_idx * res\n",
        "\n",
        "    # Initialize accumulator to 0\n",
        "    accum = tl.zeros((BLOCK_VOXEL,), dtype=tl.float32)\n",
        "\n",
        "    # Iterate over all detectors (no Split-K)\n",
        "    for det_idx in tl.range(0, num_detectors):\n",
        "        det_loc_x = tl.load(detector_x_ptr + det_idx)\n",
        "        det_loc_y = tl.load(detector_y_ptr + det_idx)\n",
        "        det_loc_z = tl.load(detector_z_ptr + det_idx)\n",
        "\n",
        "        dx = det_loc_x - vox_loc_x\n",
        "        dy = det_loc_y - vox_loc_y\n",
        "        dz = det_loc_z - vox_loc_z\n",
        "\n",
        "        dist_sq = dx * dx + dy * dy + dz * dz\n",
        "        dist_inv = tl.rsqrt(dist_sq)\n",
        "\n",
        "        time_center = (dist_sq * dist_inv * dd_inv_upsampled + 0.5).to(tl.int32)\n",
        "        t_mask = (time_center >= 0) & (time_center < num_times_upsampled)\n",
        "\n",
        "        dx_row_ptr = dx_conv_ptr + det_idx * stride_dx_d + time_center\n",
        "        mask = t_mask & v_mask\n",
        "        dx_val = tl.load(dx_row_ptr, mask=mask, other=0.0).to(tl.float32)\n",
        "\n",
        "        val_to_add = dx_val * dist_inv\n",
        "        accum += tl.where(mask, val_to_add, 0.0)\n",
        "\n",
        "    tl.store(output_ptr + v_offsets, accum, mask=v_mask)\n",
        "\n",
        "\n",
        "def transpose_operator_triton(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Transpose operator A^T*x (Autotune, no Split-K; on-the-fly voxel coordinate computation)\"\"\"\n",
        "    # Convolution part\n",
        "    x_reshaped = x.reshape(num_detectors, num_times)\n",
        "    dx_upsampling = torch.zeros(\n",
        "        (num_detectors, num_times_upsampled), device=DEVICE, dtype=torch.float32\n",
        "    )\n",
        "    dx_upsampling[:, ::adaptive_ratio] = x_reshaped\n",
        "\n",
        "    dx_conv_batch = (\n",
        "        torch.nn.functional.conv1d(\n",
        "            dx_upsampling.unsqueeze(1), conv_kernel, padding=time_interval_length_half\n",
        "        )\n",
        "        .squeeze(1)\n",
        "        .contiguous()\n",
        "    )\n",
        "\n",
        "    y = torch.empty(num_voxels, device=DEVICE, dtype=torch.float32)\n",
        "\n",
        "    grid = lambda META: (triton.cdiv(num_voxels, META[\"BLOCK_VOXEL\"]),)\n",
        "\n",
        "    transpose_kernel[grid](\n",
        "        dx_conv_batch,\n",
        "        detector_x,\n",
        "        detector_y,\n",
        "        detector_z,\n",
        "        y,\n",
        "        num_voxels,\n",
        "        num_detectors,\n",
        "        num_times_upsampled,\n",
        "        dd_inv_upsampled,\n",
        "        stride_dx_d,\n",
        "        x_start,\n",
        "        y_start,\n",
        "        z_start,\n",
        "        res,\n",
        "        num_y,\n",
        "        num_z,\n",
        "    )\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "# Custom Autograd Function\n",
        "class A_Operator_Triton_Function(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    Custom Autograd Function\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        return forward_operator_triton(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return transpose_operator_triton(grad_output)\n",
        "\n",
        "\n",
        "# Wrap Triton operators\n",
        "def A_operator_triton(x):\n",
        "    \"\"\"\n",
        "    Wrap Triton operators as Torch functions for automatic differentiation\n",
        "    \"\"\"\n",
        "    return A_Operator_Triton_Function.apply(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffed0a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vessel continuity regularization\n",
        "def vessel_continuity_loss(x, num_x, num_y, num_z, beta=0.1, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Optimized vessel continuity loss\n",
        "    1. Uses slicing instead of diff+prepend\n",
        "    2. Reuses computed results\n",
        "    \"\"\"\n",
        "    x_3d = x.reshape(num_x, num_y, num_z)\n",
        "\n",
        "    # Compute gradients using slicing (avoids prepend overhead)\n",
        "    grad_x = torch.zeros_like(x_3d)\n",
        "    grad_y = torch.zeros_like(x_3d)\n",
        "    grad_z = torch.zeros_like(x_3d)\n",
        "\n",
        "    grad_x[1:] = x_3d[1:] - x_3d[:-1]\n",
        "    grad_y[:, 1:] = x_3d[:, 1:] - x_3d[:, :-1]\n",
        "    grad_z[:, :, 1:] = x_3d[:, :, 1:] - x_3d[:, :, :-1]\n",
        "\n",
        "    # TV norm\n",
        "    grad_sq = grad_x.pow(2) + grad_y.pow(2) + grad_z.pow(2)\n",
        "    tv_norm = torch.sqrt(grad_sq + eps).sum()\n",
        "\n",
        "    # Second-order derivatives (reusing grad)\n",
        "    hxx = torch.zeros_like(x_3d)\n",
        "    hyy = torch.zeros_like(x_3d)\n",
        "    hzz = torch.zeros_like(x_3d)\n",
        "\n",
        "    hxx[1:] = grad_x[1:] - grad_x[:-1]\n",
        "    hyy[:, 1:] = grad_y[:, 1:] - grad_y[:, :-1]\n",
        "    hzz[:, :, 1:] = grad_z[:, :, 1:] - grad_z[:, :, :-1]\n",
        "\n",
        "    # Mixed partial derivatives\n",
        "    hxy = torch.zeros_like(x_3d)\n",
        "    hxz = torch.zeros_like(x_3d)\n",
        "    hyz = torch.zeros_like(x_3d)\n",
        "\n",
        "    hxy[:, 1:] = grad_x[:, 1:] - grad_x[:, :-1]\n",
        "    hxz[:, :, 1:] = grad_x[:, :, 1:] - grad_x[:, :, :-1]\n",
        "    hyz[:, :, 1:] = grad_y[:, :, 1:] - grad_y[:, :, :-1]\n",
        "\n",
        "    # Hessian Frobenius norm\n",
        "    hessian_sq = (\n",
        "        hxx.pow(2)\n",
        "        + hyy.pow(2)\n",
        "        + hzz.pow(2)\n",
        "        + 2 * (hxy.pow(2) + hxz.pow(2) + hyz.pow(2))\n",
        "    )\n",
        "    hessian_norm = torch.sqrt(hessian_sq + eps).sum()\n",
        "\n",
        "    return hessian_norm + beta * tv_norm\n",
        "\n",
        "\n",
        "# Non-negative function\n",
        "def nonnegative(z, eps=1e-8):\n",
        "    return (z + eps) * (z + eps)\n",
        "\n",
        "\n",
        "# Accelerate with torch.compile\n",
        "vessel_continuity_loss = torch.compile(vessel_continuity_loss)\n",
        "nonnegative = torch.compile(nonnegative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3d5bb5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use parameter transformation to ensure non-negativity constraint\n",
        "def gradient_descent_reconstruction_nonnegative(\n",
        "    observed_data,\n",
        "    max_iterations=50,\n",
        "    learning_rate=1e-6,\n",
        "    lambda_reg=1e-4,\n",
        "    T_0=10,  # First restart cycle length\n",
        "    T_mult=1,  # Restart cycle multiplier\n",
        "    eta_min=1e-8,  # Minimum learning rate\n",
        "    is_print=False,  # Whether to print progress\n",
        "):\n",
        "    \"\"\"\n",
        "    Iterative reconstruction with parameter transformation ensuring non-negativity constraint\n",
        "    Optimizes z = sqrt(x) to ensure x = z^2 >= 0\n",
        "    \"\"\"\n",
        "    # Initialize parameter z, actual optimization variable x = z^2\n",
        "    z = torch.zeros(num_voxels, device=DEVICE, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    # Create optimizer\n",
        "    optimizer = torch.optim.Adam([z], lr=learning_rate)\n",
        "\n",
        "    # Create cosine annealing warm restarts learning rate scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=T_0, T_mult=T_mult, eta_min=eta_min\n",
        "    )\n",
        "\n",
        "    # Create loss list\n",
        "    losses = []\n",
        "\n",
        "    # Iterative reconstruction\n",
        "    for iteration in range(max_iterations):\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Ensure non-negativity through squaring transformation\n",
        "        x = nonnegative(z)\n",
        "\n",
        "        # Forward pass: y = A * x\n",
        "        predicted_data = A_operator_triton(x)\n",
        "\n",
        "        # Compute loss function\n",
        "        data_fidelity = torch.nn.functional.mse_loss(predicted_data, observed_data)\n",
        "        regularization = lambda_reg * vessel_continuity_loss(x, num_x, num_y, num_z)\n",
        "        loss = data_fidelity + regularization\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print progress\n",
        "        if is_print:\n",
        "            losses.append(loss.item())\n",
        "            print(\n",
        "                f\"  Iter {iteration:3d}: Loss = {loss.item():.6e}, \"\n",
        "                f\"Data Fidelity = {data_fidelity.item():.6e}, \"\n",
        "                f\"Regularization = {regularization.item():.6e}, \"\n",
        "            )\n",
        "\n",
        "    print(\"Non-negative constrained gradient descent reconstruction completed!\")\n",
        "    x_final = nonnegative(z)\n",
        "    return x_final, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b29b5b45",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main program\n",
        "print(\"Starting gradient descent reconstruction...\")\n",
        "\n",
        "# Flatten observed data\n",
        "b = simulation_data.flatten().contiguous()\n",
        "\n",
        "# Reset GPU memory statistics\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Perform gradient descent reconstruction (with cosine annealing warm restarts and thresholding)\n",
        "start_event = torch.cuda.Event(enable_timing=True)\n",
        "end_event = torch.cuda.Event(enable_timing=True)\n",
        "start_event.record()\n",
        "x_reconstructed, losses = gradient_descent_reconstruction_nonnegative(\n",
        "    b,\n",
        "    max_iterations=60,\n",
        "    learning_rate=8e-2,\n",
        "    lambda_reg=1e-5,\n",
        "    T_0=30,  # First restart cycle length\n",
        "    T_mult=1,  # Restart cycle multiplier\n",
        "    eta_min=5e-4,  # Minimum learning rate\n",
        "    is_print=False,  # Whether to print progress\n",
        ")\n",
        "end_event.record()\n",
        "end_event.synchronize()\n",
        "\n",
        "# Get GPU memory statistics\n",
        "peak_mem = torch.cuda.max_memory_allocated()\n",
        "\n",
        "print(f\"Gradient descent reconstruction completed! Total time: {start_event.elapsed_time(end_event) / 1000:.3f} s\")\n",
        "print(f\"Peak GPU memory usage: {peak_mem / 1024**2:.2f} MB\")\n",
        "\n",
        "# Reshape to 3D image and save\n",
        "x_3d = x_reconstructed.reshape(num_x, num_y, num_z).detach().cpu().numpy()\n",
        "sio.savemat(GPAIR_RESULT_PATH, {GPAIR_RESULT_VAR: x_3d})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223b510b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use UBP reconstruction for comparison and save\n",
        "detector_normals = torch.zeros(detector_locations.shape[0], 3, device=DEVICE)\n",
        "detector_normals[:, 2] = -1.0\n",
        "# detector_normals = -detector_locations\n",
        "result_ubp = recon(\n",
        "    simulation_data.cpu().numpy(),\n",
        "    detector_locations.cpu().numpy(),\n",
        "    detector_normals.cpu().numpy(),\n",
        "    x_range,\n",
        "    y_range,\n",
        "    z_range,\n",
        "    res,\n",
        "    vs,\n",
        "    fs,\n",
        "    method=\"ubp\",\n",
        ")\n",
        "result_ubp = negetive_processing(result_ubp)\n",
        "sio.savemat(UBP_RESULT_PATH, {UBP_RESULT_VAR: result_ubp})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8ed31a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results\n",
        "plt.figure(figsize=(20, 10))\n",
        "cmap = \"hot\"\n",
        "\n",
        "# Plot UBP reconstruction z-axis MAP (Maximum Amplitude Projection)\n",
        "plt.subplot(2, 3, 1)\n",
        "ubp_map = result_ubp.max(axis=2)  # Maximum intensity projection along z-axis\n",
        "plt.imshow(\n",
        "    ubp_map.T,\n",
        "    cmap=cmap,\n",
        "    aspect=\"equal\",\n",
        "    origin=\"lower\",\n",
        "    extent=[x_start * 1e3, x_end * 1e3, y_start * 1e3, y_end * 1e3],\n",
        ")\n",
        "plt.colorbar(label=\"Intensity (a.u.)\")\n",
        "plt.xlabel(\"X (mm)\")\n",
        "plt.ylabel(\"Y (mm)\")\n",
        "plt.title(\"UBP Reconstruction - Z-axis MAP\")\n",
        "\n",
        "# Plot GPAIR reconstruction z-axis MAP (Maximum Amplitude Projection)\n",
        "plt.subplot(2, 3, 2)\n",
        "gpair_map = x_3d.max(axis=2)  # Maximum intensity projection along z-axis\n",
        "plt.imshow(\n",
        "    gpair_map.T,\n",
        "    cmap=cmap,\n",
        "    aspect=\"equal\",\n",
        "    origin=\"lower\",\n",
        "    extent=[x_start * 1e3, x_end * 1e3, y_start * 1e3, y_end * 1e3],\n",
        ")\n",
        "plt.colorbar(label=\"Intensity (a.u.)\")\n",
        "plt.xlabel(\"X (mm)\")\n",
        "plt.ylabel(\"Y (mm)\")\n",
        "plt.title(\"GPAIR Reconstruction - Z-axis MAP\")\n",
        "\n",
        "# Plot complete loss curve\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(losses, \"b-\", linewidth=2)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Complete Loss Curve\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.yscale(\"log\")\n",
        "\n",
        "# Plot UBP reconstruction z-axis center slice\n",
        "plt.subplot(2, 3, 4)\n",
        "center_z_idx = num_z // 2\n",
        "ubp_slice = result_ubp[:, :, center_z_idx]\n",
        "plt.imshow(\n",
        "    ubp_slice.T,\n",
        "    cmap=cmap,\n",
        "    aspect=\"equal\",\n",
        "    origin=\"lower\",\n",
        "    extent=[x_start * 1e3, x_end * 1e3, y_start * 1e3, y_end * 1e3],\n",
        ")\n",
        "plt.colorbar(label=\"Intensity (a.u.)\")\n",
        "plt.xlabel(\"X (mm)\")\n",
        "plt.ylabel(\"Y (mm)\")\n",
        "plt.title(\n",
        "    f\"UBP Reconstruction - Center Slice (z={z_start*1e3 + center_z_idx*res*1e3:.2f} mm)\"\n",
        ")\n",
        "\n",
        "# Plot GPAIR reconstruction z-axis center slice\n",
        "plt.subplot(2, 3, 5)\n",
        "center_z_idx = num_z // 2\n",
        "gpair_slice = x_3d[:, :, center_z_idx]\n",
        "plt.imshow(\n",
        "    gpair_slice.T,\n",
        "    cmap=cmap,\n",
        "    aspect=\"equal\",\n",
        "    origin=\"lower\",\n",
        "    extent=[x_start * 1e3, x_end * 1e3, y_start * 1e3, y_end * 1e3],\n",
        ")\n",
        "plt.colorbar(label=\"Intensity (a.u.)\")\n",
        "plt.xlabel(\"X (mm)\")\n",
        "plt.ylabel(\"Y (mm)\")\n",
        "plt.title(\n",
        "    f\"GPAIR Reconstruction - Center Slice (z={z_start*1e3 + center_z_idx*res*1e3:.2f} mm)\"\n",
        ")\n",
        "\n",
        "# Plot loss curve for the last 10 iterations\n",
        "plt.subplot(2, 3, 6)\n",
        "last_n = min(10, len(losses))\n",
        "plt.plot(\n",
        "    range(len(losses) - last_n, len(losses)),\n",
        "    losses[-last_n:],\n",
        "    \"r-\",\n",
        "    linewidth=2,\n",
        "    marker=\"o\",\n",
        ")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(f\"Last {last_n} Iterations Loss Curve\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Display results\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
